#!/usr/bin/env python3
"""
ê°„ë‹¨í•œ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python test_crawling.py <ë„¤ì´ë²„_ë¸”ë¡œê·¸_URL>

ì˜ˆì‹œ:
    python test_crawling.py https://blog.naver.com/example-post
"""

import sys
import json
from typing import Optional

# src ëª¨ë“ˆ ì„í¬íŠ¸
from src.extractor import NaverBlogExtractor


def print_colored(text: str, color: str = "white") -> None:
    """ì»¬ëŸ¬ ì¶œë ¥ í—¬í¼ í•¨ìˆ˜."""
    colors = {
        "green": "\033[92m",
        "red": "\033[91m",
        "yellow": "\033[93m",
        "blue": "\033[94m",
        "white": "\033[0m",
        "bold": "\033[1m",
    }
    end = "\033[0m"
    print(f"{colors.get(color, '')}{text}{end}")


def test_crawling(url: str) -> None:
    """
    ë‹¨ì¼ URLì—ì„œ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰.

    Args:
        url: í…ŒìŠ¤íŠ¸í•  ë„¤ì´ë²„ ë¸”ë¡œê·¸ URL
    """
    print_colored("="*80, "blue")
    print_colored("ë„¤ì´ë²„ ë¸”ë¡œê·¸ AI ì½˜í…ì¸  ì¶”ì¶œ í…ŒìŠ¤íŠ¸", "bold")
    print_colored("="*80, "blue")
    print()

    print_colored(f"ëŒ€ìƒ URL: {url}", "white")
    print_colored("ê²€ìƒ‰ ë‹¨ì–´: yarn, ì‹¤, ë°”ëŠ˜, ì‚¬ìš©ì‹¤", "white")
    print()

    # Extractor ì´ˆê¸°í™” (ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©)
    print_colored("â³ Llama 3.2 1B ëª¨ë¸ ë¡œë”© ì¤‘...", "yellow")

    from scrapegraphai.graphs import SmartScraperGraph

    # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸: 4ê°œ ë‹¨ì–´ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ëœ ë¬¸ì¥ ì¶”ì¶œ
    custom_prompt = """
    Find and extract the FIRST sentence that contains ANY of these terms:
    1. "yarn"
    2. "ì‹¤" (Korean word for thread)
    3. "ë°”ëŠ˜" (Korean word for needle)
    4. "ì‚¬ìš©ì‹¤" (Korean term for yarn/thread used)

    Return ONLY the complete sentence in JSON format with this structure:
    {
        "sentence": "the extracted sentence here",
        "found": true
    }

    If no sentence contains any of these terms, return:
    {
        "sentence": null,
        "found": false
    }
    """

    # ScrapeGraphAI ì„¤ì •
    graph_config = {
        "llm": {
            "model": "ollama/llama3.2:1b",
            "temperature": 0.0,
            "format": "json",
        },
        "embeddings": {
            "model": "ollama/llama3.2:1b",
        },
        "headless": True,
        "verbose": False,
    }

    # í¬ë¡¤ë§ ìˆ˜í–‰
    print_colored("ğŸ” ì½˜í…ì¸  ì¶”ì¶œ ì¤‘...", "yellow")

    try:
        smart_scraper = SmartScraperGraph(
            prompt=custom_prompt,
            source=url,
            config=graph_config
        )

        raw_result = smart_scraper.run()

        # ê²°ê³¼ íŒŒì‹±
        from src.extractor import ExtractionResult

        if raw_result and isinstance(raw_result, dict):
            found = raw_result.get("found", False)
            sentence = raw_result.get("sentence")

            if found and sentence:
                result = ExtractionResult(
                    extracted_sentence=sentence,
                    source_url=url,
                    success=True
                )
            else:
                result = ExtractionResult(
                    extracted_sentence=None,
                    source_url=url,
                    success=False,
                    error_message="No sentence containing any of the search terms found"
                )
        else:
            result = ExtractionResult(
                extracted_sentence=None,
                source_url=url,
                success=False,
                error_message="Invalid extraction result format"
            )
    except Exception as e:
        result = ExtractionResult(
            extracted_sentence=None,
            source_url=url,
            success=False,
            error_message=f"Extraction error: {str(e)}"
        )

    print()
    print_colored("="*80, "blue")
    print_colored("ğŸ“Š ì¶”ì¶œ ê²°ê³¼ (JSON)", "bold")
    print_colored("="*80, "blue")
    print()

    # JSON ê²°ê³¼ ì¶œë ¥
    json_str = result.to_json()
    print(json_str)
    print()

    # ê²°ê³¼ ìš”ì•½
    print_colored("="*80, "blue")
    if result.success:
        print_colored("âœ… ì„±ê³µ!", "green")
        print_colored(f"ì¶”ì¶œëœ ë¬¸ì¥: {result.extracted_sentence}", "green")
    else:
        print_colored("âŒ ì‹¤íŒ¨", "red")
        print_colored(f"ì˜¤ë¥˜: {result.error_message}", "red")
    print_colored("="*80, "blue")


def main() -> int:
    """ë©”ì¸ í•¨ìˆ˜."""
    if len(sys.argv) < 2:
        print_colored("âŒ ì‚¬ìš©ë²• ì˜¤ë¥˜", "red")
        print()
        print("ì‚¬ìš©ë²•:")
        print(f"  python {sys.argv[0]} <ë„¤ì´ë²„_ë¸”ë¡œê·¸_URL>")
        print()
        print("ì˜ˆì‹œ:")
        print(f"  python {sys.argv[0]} https://blog.naver.com/example-post")
        return 1

    url = sys.argv[1]

    # URL ê²€ì¦ (ê°„ë‹¨í•œ ì²´í¬)
    if not url.startswith("http"):
        print_colored("âš ï¸  ê²½ê³ : ìœ íš¨í•œ URLì´ ì•„ë‹ ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "yellow")
        print()

    try:
        test_crawling(url)
        return 0
    except KeyboardInterrupt:
        print()
        print_colored("\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨", "yellow")
        return 130
    except Exception as e:
        print()
        print_colored(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}", "red")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
